{"cells":[{"cell_type":"markdown","metadata":{"id":"1P-JH5tqahK4"},"source":["Install the required libraries if you have not already done so, then restart the kernel"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sMJmDdnXahK6"},"outputs":[],"source":["%pip install biopython==1.81 pandas numpy tqdm ipywidgets"]},{"cell_type":"markdown","metadata":{"id":"5z0Vh5DyahK7"},"source":["Import libraries and necessary encoding information"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"fGt0n9gjahK8"},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\nusef\\anaconda3\\envs\\biopython\\lib\\site-packages\\Bio\\pairwise2.py:278: BiopythonDeprecationWarning: Bio.pairwise2 has been deprecated, and we intend to remove it in a future release of Biopython. As an alternative, please consider using Bio.Align.PairwiseAligner as a replacement, and contact the Biopython developers if you still need the Bio.pairwise2 module.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["Loaded library components...\n"]}],"source":["#Import libraries\n","from Bio import SeqIO, pairwise2\n","from Bio.Seq import Seq\n","from tqdm import tqdm\n","from tqdm.notebook import tqdm_notebook\n","import pandas as pd\n","import numpy as np\n","import timeit\n","import time\n","\n","#Import utility functions\n","from utils import toolkit as tk\n","\n","#Import the needed classes\n","from classes.Log import Logging\n","from classes.Codes import Codes\n","\n","# Create a class instance using the encoding info located in /library\n","main=Codes(n_cycles=2)\n","\n","# Begin logging operations\n","log_records=Logging()\n","user_inputs={}"]},{"cell_type":"markdown","metadata":{"id":"lnIOjajuahK8"},"source":["Specify Inputs"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"z0dI5m08ahK8"},"outputs":[],"source":["##### INPUTS #####\n","# (Change as needed according according to the library's encoding scheme)\n","# Note that under the current encoding scheme, the PCR1 code is the first 6 bp so searching for it is unnecessary.\n","\n","# Provide a short name for organizing the results in the output folder\n","user_inputs['NAME']= 'TestBatch1'\n","\n","#####################\n","### INDEX INPUTS  ###\n","#####################\n","\n","#This should be the number of BP that precedes the first bb encoding region (BB1)\n","user_inputs['BB1_START_IDX'] = 30\n","\n","#This should be the number of BP that precedes the second bb encoding region (BB2)\n","user_inputs['BB2_START_IDX'] = 51\n","\n","#This should be the number of BP that precedes the third bb encoding region (BB3)\n","user_inputs['BB3_START_IDX'] = None\n","\n","#This should be the number of BP that precedes the second pcr encoding region (PCR2)\n","user_inputs['PCR2_START_IDX'] = 75\n","\n","\n","##############################\n","### OTHER REQUIRED INPUTS  ###\n","##############################\n","\n","#The illumina adapter sequence used to preprocess the fastq file.\n","#Only reads containing this sequence will be extracted for analysis.\n","user_inputs['ADAPT_SEQ']='GATCGGAAGAGCACACGTCTG'\n","\n","#Specify the length of the codes used for BB encoding\n","user_inputs['BB_ENCODING_LEN'] = 7\n","\n","#Specify the length of the codes used for PCR encoding\n","user_inputs['PCR_ENCODING_LEN'] = 6\n","\n","#Specify the max number of mismatch errors to allow in the encoding sequences\n","user_inputs['ENCODING_TOLERANCE'] = 1\n","\n","# Define the path to your raw FASTQ file (This is the name of the file that will be submitted for preprocessing)\n","user_inputs['RAW_FASTQ_FILE'] = \"ExampleData.fastq\"\n","\n","# Define the name you wish to use for saving the preprocessed FASTQ file (This will be the name of the preprocessing output file)\n","user_inputs['PROC_FASTQ_FILE'] = \"Preprocessed_ExampleData.txt\"\n","\n","\n","\n","########################\n","### OPTIONAL INPUTS  ###\n","########################\n","\n","#Set to \"True\" to test only the first N_TEST_SEQUENCES\n","#Set to 'False\" to process the entire sequencing file\n","user_inputs['TEST_RUN']=False\n","user_inputs['N_TEST_SEQUENCES']=200000\n","\n","\n","main.load_user_inputs(user_inputs)\n","log_records.user_inputs=user_inputs"]},{"cell_type":"markdown","metadata":{"id":"a7chwazHahK8"},"source":["1) Process the raw fastq file <br>\n"," * This will find and extract only codes containing the query sequence and add them to the output file."]},{"cell_type":"code","execution_count":3,"metadata":{"id":"4QF1BzpQahK9"},"outputs":[{"name":"stderr","output_type":"stream","text":["0it [00:00, ?it/s]"]},{"name":"stderr","output_type":"stream","text":["200000it [00:02, 88323.47it/s]"]},{"name":"stdout","output_type":"stream","text":["Wrote 152825 sequences to outputs/TestBatch1/Preprocessed_ExampleData.txt\n","47175 sequences were removed.\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["'''\n","The preprocessing step performed here only identifies and aggregates sequences containing the illumina adapter sequences.\n","Trimming the adapter sequences offers no significant benefit and running a program or online tool using \"cutadapt\"\n","(as done previously) is not necessary.\n","'''\n","\n","\n","#Preprocess the fastq file and save a .txt file to the outputs folder\n","start_time = time.time()\n","n_records, w_records=main.preprocess_fastq()\n","\n","#Store logging information for preprocessing\n","log_records.store_preprocessing_records(n_records, w_records, round(time.time()-start_time, ndigits=2))\n","\n","#Print the results\n","print(f\"Wrote {w_records} sequences to outputs/{user_inputs['NAME']}/{user_inputs['PROC_FASTQ_FILE']}\")\n","print(f\"{n_records-w_records} sequences were removed.\")"]},{"cell_type":"markdown","metadata":{"id":"MjRqu-nDahK9"},"source":["**2) Extract the BB encoding sequences from the processed fastq file**"]},{"cell_type":"markdown","metadata":{"id":"ZLS7dJrPahK9"},"source":["\n"," * This will find and extract sequences at indices that theoretically correspond to the encoding sequences\n"," - Any sequencing or pcr errors are not accounted for."]},{"cell_type":"code","execution_count":4,"metadata":{"id":"wHJwAJ_QahK9"},"outputs":[{"name":"stdout","output_type":"stream","text":["Processing 152825 sequences...\n"]},{"name":"stderr","output_type":"stream","text":["152825it [00:00, 896293.99it/s]\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>bb1</th>\n","      <th>bb2</th>\n","      <th>pcr1</th>\n","      <th>pcr2</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>CATTCCT</td>\n","      <td>TAGGAAC</td>\n","      <td>AGAGAG</td>\n","      <td>ATGATA</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>TGGTCCC</td>\n","      <td>GTAGGAT</td>\n","      <td>ACAGCA</td>\n","      <td>ATCGGA</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>TATGGTT</td>\n","      <td>TCTCCGA</td>\n","      <td>TATCAC</td>\n","      <td>TGTCAG</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>TAGTCCT</td>\n","      <td>TTACGGT</td>\n","      <td>ACTCTG</td>\n","      <td>TGTCAG</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>GTCCATG</td>\n","      <td>GGTATTG</td>\n","      <td>ACTGAT</td>\n","      <td>GTCACG</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       bb1      bb2    pcr1    pcr2\n","0  CATTCCT  TAGGAAC  AGAGAG  ATGATA\n","1  TGGTCCC  GTAGGAT  ACAGCA  ATCGGA\n","2  TATGGTT  TCTCCGA  TATCAC  TGTCAG\n","3  TAGTCCT  TTACGGT  ACTCTG  TGTCAG\n","4  GTCCATG  GGTATTG  ACTGAT  GTCACG"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["t0=timeit.default_timer()\n","main.extract_codes()\n","log_records.store_extraction_records(t0, timeit.default_timer())\n","\n","#Preview the code_df\n","main.code_df.head()"]},{"cell_type":"markdown","metadata":{"id":"W0F7eBE0ahK9"},"source":["3) Search for and correct encoding errors"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d84e1388456f47e38928b0ec3b5a7c31","version_major":2,"version_minor":0},"text/plain":["Correcting codes:   0%|          | 0/152825 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f67bff07850746278c01dd98fad788c4","version_major":2,"version_minor":0},"text/plain":["Correcting codes:   0%|          | 0/152825 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1ae82802f00640d1bb276574cb28c4dd","version_major":2,"version_minor":0},"text/plain":["Correcting codes:   0%|          | 0/152825 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4cefa07b42634838b2d157bde3b472a9","version_major":2,"version_minor":0},"text/plain":["Correcting codes:   0%|          | 0/152825 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Rows before correction:  152825\n","pcr1| Corrected: 0, Rejected: 15230, Attrition Rate: 0.9\n","pcr2| Corrected: 0, Rejected: 38119, Attrition Rate: 0.7\n","bb1| Corrected: 0, Rejected: 26778, Attrition Rate: 0.66\n","bb2| Corrected: 0, Rejected: 34988, Attrition Rate: 0.63\n","Rows after correction:  95862\n"]}],"source":["tqdm_notebook.pandas(desc=\"Correcting codes\")\n","code_names=list(main.code_dict.keys())\n","correction_dict={}\n","rows_before=main.code_df.shape[0]\n","\n","#For each code, update the code_df with additional columns for codes with correctable/uncorrectable errors\n","times=[]\n","for code in code_names:\n","    start_time = time.time()\n","    code_df=tk.update_code_df(main.code_df, code, main.code_dict[code], correction_mode='strict')\n","    times.append(round(time.time()-start_time, ndigits=2))\n","\n","#Create a copy of the code_df for filtering uncorrectable errors\n","corrected_df = code_df.copy()\n","\n","#Create a corrected df containing only codes from the screen with less than or equal to the specified max_errors\n","#The corrected df is modified in place, iteratively filtering out rows if code outside of error tolerance\n","#The correction dict keeps record of the codes corrected or rejected (and the cumulative attrition) after each iteration \n","for idx, code in enumerate(code_names):\n","    corrected_df, correction_dict=tk.filter_code_df(code_df, corrected_df, code, correction_dict)\n","\n","\n","time_dict=dict(zip(code_names, times))\n","rows_after=corrected_df.shape[0]\n","log_records.store_correction_records(rows_before, rows_after, correction_dict, time_dict)"]},{"cell_type":"markdown","metadata":{"id":"LVQN0v8vahK-"},"source":["4) Count and organize the sequence data into a final dataframe"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"AwnHzwbVahK-"},"outputs":[],"source":["#create a new df with the codes that will be used for counting\n","counted_df=pd.DataFrame()\n","counted_df['bb1']=corrected_df['corrected_bb1']\n","counted_df['bb2']=corrected_df['corrected_bb2']\n","counted_df['pcr1']=corrected_df['corrected_pcr1']\n","counted_df['pcr2']=corrected_df['corrected_pcr2']\n","\n","#group the counted df in place\n","counted_df = counted_df.groupby(['bb1', 'bb2', 'pcr1', 'pcr2']).size().reset_index(name='Count')\n","\n","#translate the pcr and bb codes and add them into the counted df\n","counted_df['pcr1_id']=counted_df['pcr1'].apply(lambda pcr1: main.pcr1_code_dict[pcr1])\n","counted_df['pcr2_id']=counted_df['pcr2'].apply(lambda pcr2: main.pcr2_code_dict[pcr2])\n","counted_df['bb1_id']=counted_df['bb1'].apply(lambda bb1: main.bb1_code_dict[bb1])\n","counted_df['bb1_Smiles']=counted_df['bb1_id'].apply(lambda bb1: main.bb1_smiles_dict[bb1])\n","counted_df['bb2_id']=counted_df['bb2'].apply(lambda bb2: main.bb2_code_dict[bb2])\n","counted_df['bb2_Smiles']=counted_df['bb2_id'].apply(lambda bb2: main.bb2_smiles_dict[bb2])\n","\n","#pivot the counted_df (use pcr codes for the columns and index the rows according to BBs/Smiles)\n","final_df = counted_df.pivot(index=['bb1_id', 'bb1_Smiles','bb2_id', 'bb2_Smiles'], columns=['pcr1_id','pcr2_id'], values='Count').reset_index()\n","\n","#fill the nan values with 0\n","final_df=final_df.fillna(0)"]},{"cell_type":"markdown","metadata":{"id":"KsJU1zFgahK-"},"source":["5. Output the results in two csv files:\n","    * 1) As absolute sequence counts\n","    * 2) As normalized sequence counts\n"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"mQ2wsVnvahK-"},"outputs":[],"source":["# Merge column names\n","merged_columns = [''.join(col).strip() for col in final_df.columns.values]\n","merged_columns = [str(col).replace('1a-','') for col in merged_columns]\n","merged_columns = [str(col).replace('1b-','') for col in merged_columns]\n","\n","# Assign merged column names to DataFrame\n","final_df.columns = merged_columns\n","\n","# Output the final DataFrame to csv with absolute sequence counts\n","final_df.to_csv(f'{main.output_location}/Results_AbsSeqCounts.csv')\n","\n","#Convert to normalized sequence counts\n","#pcr_list=list(pcr_primer_1.values())\n","for pcr in final_df.columns[4:]:\n","    sum_value = final_df[pcr].sum()\n","    final_df[pcr]=final_df[pcr].apply(lambda count: (count/sum_value)*(len(final_df)))\n","\n","# Output the final DataFrame to csv with normalized sequence counts\n","final_df.to_csv(f'{main.output_location}/Results_NormSeqCounts.csv')\n","\n","# Output a log record\n","log_records.generate_log(f'{main.output_location}/Log.txt')"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"my-rdkit-env","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.8"}},"nbformat":4,"nbformat_minor":0}
