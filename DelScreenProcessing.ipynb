{"cells":[{"cell_type":"markdown","metadata":{"id":"1P-JH5tqahK4"},"source":["Install the required libraries if you have not already done so, then restart the kernel"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sMJmDdnXahK6"},"outputs":[],"source":["%pip install biopython==1.81 pandas numpy tqdm ipywidgets"]},{"cell_type":"markdown","metadata":{"id":"5z0Vh5DyahK7"},"source":["Import libraries and necessary encoding information"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fGt0n9gjahK8"},"outputs":[],"source":["#Import libraries\n","from Bio import SeqIO, pairwise2\n","from Bio.Seq import Seq\n","from tqdm import tqdm\n","from tqdm.notebook import tqdm_notebook\n","import pandas as pd\n","import numpy as np\n","import timeit\n","import time\n","\n","#Import utility functions\n","from utils import toolkit as tk\n","\n","#Import the needed classes\n","from classes.Log import Logging\n","from classes.Codes import Codes\n","\n","# Create a class instance using the encoding info located in /library\n","main=Codes(n_cycles=2)\n","\n","# Begin logging operations\n","log_records=Logging()\n","user_inputs={}"]},{"cell_type":"markdown","metadata":{"id":"lnIOjajuahK8"},"source":["Specify Inputs"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"z0dI5m08ahK8"},"outputs":[],"source":["##### INPUTS #####\n","# (Change as needed according according to the library's encoding scheme)\n","# Note that under the current encoding scheme, the PCR1 code is the first 6 bp so searching for it is unnecessary.\n","\n","# Provide a short name for organizing the results in the output folder\n","user_inputs['NAME']= 'TestBatch1'\n","\n","#####################\n","### INDEX INPUTS  ###\n","#####################\n","\n","#This should be the number of BP that precedes the first bb encoding region (BB1)\n","user_inputs['BB1_START_IDX'] = 30\n","\n","#This should be the number of BP that precedes the second bb encoding region (BB2)\n","user_inputs['BB2_START_IDX'] = 51\n","\n","#This should be the number of BP that precedes the second bb encoding region (BB3)\n","user_inputs['BB3_START_IDX'] = None\n","\n","#This should be the number of BP that precedes the second pcr encoding region (PCR2)\n","user_inputs['PCR2_START_IDX'] = 75\n","\n","\n","##############################\n","### OTHER REQUIRED INPUTS  ###\n","##############################\n","\n","#The illumina adapter sequence used to preprocess the fastq file.\n","#Only reads containing this sequence will be extracted for analysis.\n","user_inputs['ADAPT_SEQ']='GATCGGAAGAGCACACGTCTG'\n","\n","#Specify the length of the codes used for BB encoding\n","user_inputs['BB_ENCODING_LEN'] = 7\n","\n","#Specify the length of the codes used for PCR encoding\n","user_inputs['PCR_ENCODING_LEN'] = 6\n","\n","#Specify the max number of mismatch errors to allow in the encoding sequences\n","user_inputs['ENCODING_TOLERANCE'] = 1\n","\n","# Define the path to your raw FASTQ file (This is the name of the file that will be submitted for preprocessing)\n","user_inputs['RAW_FASTQ_FILE'] = \"ExampleData.fastq\"\n","\n","# Define the name you wish to use for saving the preprocessed FASTQ file (This will be the name of the preprocessing output file)\n","user_inputs['PROC_FASTQ_FILE'] = \"Preprocessed_ExampleData.txt\"\n","\n","\n","\n","########################\n","### OPTIONAL INPUTS  ###\n","########################\n","\n","#Set to \"True\" to test only the first N_TEST_SEQUENCES\n","#Set to 'False\" to process the entire sequencing file\n","user_inputs['TEST_RUN']=False\n","user_inputs['N_TEST_SEQUENCES']=200000\n","\n","\n","main.load_user_inputs(user_inputs)\n","log_records.user_inputs=user_inputs"]},{"cell_type":"markdown","metadata":{"id":"a7chwazHahK8"},"source":["1) Process the raw fastq file <br>\n"," * This will find and extract only codes containing the query sequence and add them to the output file."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4QF1BzpQahK9"},"outputs":[],"source":["'''\n","The preprocessing step performed here only identifies and aggregates sequences containing the illumina adapter sequences.\n","Trimming the adapter sequences offers no significant benefit and running a program or online tool using \"cutadapt\"\n","(as done previously) is not necessary.\n","'''\n","\n","\n","#Preprocess the fastq file and save a .txt file to the outputs folder\n","start_time = time.time()\n","n_records, w_records=main.preprocess_fastq()\n","\n","#Store logging information for preprocessing\n","log_records.store_preprocessing_records(n_records, w_records, round(time.time()-start_time, ndigits=2))\n","\n","#Print the results\n","print(f\"Wrote {w_records} sequences to outputs/{user_inputs['NAME']}/{user_inputs['PROC_FASTQ_FILE']}\")\n","print(f\"{n_records-w_records} sequences were removed.\")"]},{"cell_type":"markdown","metadata":{"id":"MjRqu-nDahK9"},"source":["**2) Extract the BB encoding sequences from the processed fastq file**"]},{"cell_type":"markdown","metadata":{"id":"ZLS7dJrPahK9"},"source":["\n"," * This will find and extract sequences at indices that theoretically correspond to the encoding sequences\n"," - Any sequencing or pcr errors are not accounted for."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wHJwAJ_QahK9"},"outputs":[],"source":["t0=timeit.default_timer()\n","main.extract_codes()\n","log_records.store_extraction_records(t0, timeit.default_timer())\n","\n","#Preview the code_df\n","main.code_df.head()"]},{"cell_type":"markdown","metadata":{"id":"W0F7eBE0ahK9"},"source":["3) Search for and correct encoding errors"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5oOVj3afahK9"},"outputs":[],"source":["tqdm_notebook.pandas(desc=\"Correcting codes\")\n","code_names=list(main.code_dict.keys())\n","correction_dict={}\n","rows_before=main.code_df.shape[0]\n","\n","#For each code, update the code_df with additional columns for codes with correctable/uncorrectable errors\n","times=[]\n","for code in code_names:\n","    start_time = time.time()\n","    code_df=tk.update_code_df(main.code_df, code, main.code_dict[code])\n","    times.append(round(time.time()-start_time, ndigits=2))\n","\n","#Create a copy of the code_df for filtering uncorrectable errors\n","corrected_df = code_df.copy()\n","\n","#Create a corrected df containing only codes from the screen with less than or equal to the specified max_errors\n","#The corrected df is modified in place, iteratively filtering out rows for each code outside of tolerance\n","for idx, code in enumerate(code_names):\n","    corrected_df, correction_dict=tk.filter_code_df(code_df, corrected_df, code, correction_dict)\n","\n","\n","time_dict=dict(zip(code_names, times))\n","rows_after=corrected_df.shape[0]\n","log_records.store_correction_records(rows_before, rows_after, correction_dict, time_dict)"]},{"cell_type":"markdown","metadata":{"id":"LVQN0v8vahK-"},"source":["4) Count and organize the sequence data into a final dataframe"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AwnHzwbVahK-"},"outputs":[],"source":["#create a new df with the codes that will be used for counting\n","counted_df=pd.DataFrame()\n","counted_df['bb1']=corrected_df['corrected_bb1']\n","counted_df['bb2']=corrected_df['corrected_bb2']\n","counted_df['pcr1']=corrected_df['corrected_pcr1']\n","counted_df['pcr2']=corrected_df['corrected_pcr2']\n","\n","#group the counted df in place\n","counted_df = counted_df.groupby(['bb1', 'bb2', 'pcr1', 'pcr2']).size().reset_index(name='Count')\n","\n","#translate the pcr and bb codes and add them into the counted df\n","counted_df['pcr1_id']=counted_df['pcr1'].apply(lambda pcr1: main.pcr1_code_dict[pcr1])\n","counted_df['pcr2_id']=counted_df['pcr2'].apply(lambda pcr2: main.pcr2_code_dict[pcr2])\n","counted_df['bb1_id']=counted_df['bb1'].apply(lambda bb1: main.bb1_code_dict[bb1])\n","counted_df['bb1_Smiles']=counted_df['bb1_id'].apply(lambda bb1: main.bb1_smiles_dict[bb1])\n","counted_df['bb2_id']=counted_df['bb2'].apply(lambda bb2: main.bb2_code_dict[bb2])\n","counted_df['bb2_Smiles']=counted_df['bb2_id'].apply(lambda bb2: main.bb2_smiles_dict[bb2])\n","\n","#pivot the counted_df (use pcr codes for the columns and index the rows according to BBs/Smiles)\n","final_df = counted_df.pivot(index=['bb1_id', 'bb1_Smiles','bb2_id', 'bb2_Smiles'], columns=['pcr1_id','pcr2_id'], values='Count').reset_index()\n","\n","#fill the nan values with 0\n","final_df=final_df.fillna(0)"]},{"cell_type":"markdown","metadata":{"id":"KsJU1zFgahK-"},"source":["5. Output the results in two csv files:\n","    * 1) As absolute sequence counts\n","    * 2) As normalized sequence counts\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mQ2wsVnvahK-"},"outputs":[],"source":["# Merge column names\n","merged_columns = [''.join(col).strip() for col in final_df.columns.values]\n","merged_columns = [str(col).replace('1a-','') for col in merged_columns]\n","merged_columns = [str(col).replace('1b-','') for col in merged_columns]\n","\n","# Assign merged column names to DataFrame\n","final_df.columns = merged_columns\n","\n","# Output the final DataFrame to csv with absolute sequence counts\n","final_df.to_csv(f'{main.output_location}/Results_AbsSeqCounts.csv')\n","\n","#Convert to normalized sequence counts\n","#pcr_list=list(pcr_primer_1.values())\n","for pcr in final_df.columns[4:]:\n","    sum_value = final_df[pcr].sum()\n","    final_df[pcr]=final_df[pcr].apply(lambda count: (count/sum_value)*(len(final_df)))\n","\n","# Output the final DataFrame to csv with normalized sequence counts\n","final_df.to_csv(f'{main.output_location}/Results_NormSeqCounts.csv')\n","\n","# Output a log record\n","log_records.generate_log(f'{main.output_location}/Log.txt')"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"my-rdkit-env","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.8"}},"nbformat":4,"nbformat_minor":0}
